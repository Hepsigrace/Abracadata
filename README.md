# Abracadata

Project Description: This project dives into the intricacies of Large Language Models (LLMs) such as ChatGPT, focusing on their ability to execute zero-shot tasks and the challenges that come with it. We're addressing critical issues such as hallucinations and inconsistencies in LLM outputs, which are barriers to deploying these models in sensitive applications like automated therapy and legal document evaluation.

Our investigation centers around creating a dataset using ChatGPT-generated responses, which we'll scrutinize for hallucinations and consistency. This includes prompt engineering to elicit complex responses and employing natural language processing (NLP) techniques to evaluate the data.

Goals:
•	To understand and document the behavior of LLMs in response to various prompts.

•	To develop a methodology for detecting hallucinations and assessing the consistency of LLMs.

•	To test the hypothesis of whether LLMs exhibit patterns of consistent behavior or hallucinations.

Data Sets: Datasets will be generated in-house using responses from ChatGPT and Gemini.

Research Significance: Our findings will add to the collective understanding of LLMs' applications and limitations, guiding future implementations and research in this field.

Project Deliverables:
•	A comprehensive final report detailing our methodologies, findings, and implications.

•	A presentation encapsulating our research insights.

•	A GitHub repository containing our datasets and code artifacts, illustrating our work's reproducibility and transparency.
